{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WeSAD_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sa-y-an/ywc/blob/main/WeSAD_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJpFvCuQfaDh",
        "outputId": "e8fb1f49-cf2e-450f-d917-7a75e791e930"
      },
      "source": [
        "#download the cleaned data \n",
        "!gdown --id 1XJLa-kXOT_cBORvOgRf84c3WnEkLX-dH"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XJLa-kXOT_cBORvOgRf84c3WnEkLX-dH\n",
            "To: /content/wdata.zip\n",
            "740MB [00:06, 121MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y00Eo26Zfg-I"
      },
      "source": [
        "!unzip -q wdata.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Piz4yNRofoB8"
      },
      "source": [
        "source = '/content/wdata'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8YnfYMAfc2v"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHW3gdabXL0Q"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeKnPr7DaImh"
      },
      "source": [
        "FEATURE_COLUMNS = ['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xpOvBoOkhdg"
      },
      "source": [
        "def two_class(x:int) :\n",
        "    if x == 2 :\n",
        "        return 0\n",
        "        \n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGfauph8P1h_",
        "outputId": "0cb0a446-6d0f-471e-ab69-dadfa7753e7a"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL96gctmTAvX"
      },
      "source": [
        "def smoting_data(file_num : int ) :\n",
        "\n",
        "    modal_file = source + \"/Modalities/S{}_train.csv\".format(file_num)\n",
        "    # labels = pd.read_csv(label_file)\n",
        "    modals = pd.read_csv(modal_file)\n",
        "    modals.drop(['Unnamed: 0'], axis = 1, inplace= True)\n",
        "\n",
        "    modals.drop(['series_id'], axis = 1 , inplace = True)\n",
        "\n",
        "    labels = modals['label']\n",
        "\n",
        "    modals.drop(['label'] , axis= 1 , inplace = True )\n",
        "\n",
        "    modals = modals.to_numpy()\n",
        "    labels.to_numpy()\n",
        "\n",
        "    oversample = SMOTE(random_state = 42 )\n",
        "    modals, labels = oversample.fit_resample(modals, labels)\n",
        "    df = pd.DataFrame(modals , columns = FEATURE_COLUMNS )\n",
        "    df['label'] = labels\n",
        "\n",
        "    return df       "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptSmxkhUQQR"
      },
      "source": [
        "def create_sequences(data) : \n",
        "\n",
        "    seq = np.array([], dtype='int')\n",
        "\n",
        "    for i in range(int(len(data)/700)) :\n",
        "        temp = np.ones(shape = 700,dtype='int')*i\n",
        "        seq = np.append(seq,temp)\n",
        "\n",
        "\n",
        "    data['series_id'] = seq\n",
        "\n",
        "    y_train = pd.DataFrame()\n",
        "    y_train['series_id'] = data['series_id']\n",
        "    y_train['label'] = data['label']\n",
        "\n",
        "\n",
        "\n",
        "    y_train = y_train.groupby(['series_id']).mean()\n",
        "    temp = range(int(len(data)/700))\n",
        "\n",
        "    y_train['series_id'] = temp\n",
        "\n",
        "    if (data.series_id.value_counts() == 700 ).sum() != len(y_train) :\n",
        "        return \"Values dont match\"\n",
        "\n",
        "\n",
        "    return data, y_train"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeDTjHySZhRS"
      },
      "source": [
        "def create_train_dataframe(file_num:int) :\n",
        "    '''Returns modals and labels for a particular file num'''\n",
        "\n",
        "    if file_num > 17 or file_num <2 :\n",
        "        return \"Give an entry between 2 and 17 \"\n",
        "\n",
        "    elif file_num == 12 :\n",
        "        return \"S12 is absent\"\n",
        "\n",
        "    df = smoting_data(file_num)\n",
        "    modals, labels = create_sequences(df)\n",
        "\n",
        "\n",
        "    series_id = modals[['series_id']]\n",
        "    modals.drop(['label'], axis = 1, inplace= True)\n",
        "    \n",
        "\n",
        "    # uncomment when using two class classification\n",
        "    # labels['label'] = labels['label'].apply(two_class)\n",
        "\n",
        "\n",
        "    x_shape = (modals.series_id.value_counts() == 700).sum()\n",
        "\n",
        "    if (modals.series_id.value_counts() == 700 ).sum() != len(labels) :\n",
        "        return \"Data sizes are incompatible, modal count = {} and label count = {}\".format(x_shape, len(labels) )\n",
        "\n",
        "    strn = \"Data sizes are - modal count = {} and label count = {}\".format(x_shape, len(labels) )\n",
        "    print(strn)\n",
        "    print(\" Modals and labels created ..\")\n",
        "\n",
        "\n",
        "    modals.drop(['series_id'], axis= 1, inplace = True)\n",
        "    columns = modals.columns\n",
        "\n",
        "    \n",
        "\n",
        "    # perform a robust scaler transform of the dataset\n",
        "    trans = MinMaxScaler()\n",
        "    modals = trans.fit_transform(modals)\n",
        "\n",
        "    modals = pd.DataFrame(modals,columns= columns)\n",
        "    modals['series_id'] = series_id\n",
        "\n",
        "\n",
        "    print(\"Data Normalized with MIn MAx scaler\")\n",
        "\n",
        "    return modals,labels"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH-dEZXJfwLJ"
      },
      "source": [
        "def create_test_dataframe(file_num:int) :\n",
        "    '''Returns modals and labels for a particular file num'''\n",
        "\n",
        "    if file_num > 17 or file_num <2 :\n",
        "        return \"Give an entry between 2 and 17 \"\n",
        "\n",
        "    elif file_num == 12 :\n",
        "        return \"S12 is absent\"\n",
        "\n",
        "    label_file = source + \"/Labels/S{}_label.csv\".format(file_num)\n",
        "    modal_file = source + \"/Modalities/S{}_train.csv\".format(file_num)\n",
        "    labels = pd.read_csv(label_file)\n",
        "    modals = pd.read_csv(modal_file)\n",
        "    modals.drop(['Unnamed: 0'], axis = 1, inplace= True)\n",
        "    print(modals.columns)\n",
        "    series_id = modals[['series_id']]\n",
        "    modals.drop(['label'], axis = 1, inplace= True)\n",
        "    labels.drop(['series_id.1'], axis = 1 ,  inplace = True)\n",
        "\n",
        "    # uncomment when using two class classification\n",
        "    # labels['label'] = labels['label'].apply(two_class)\n",
        "\n",
        "\n",
        "    x_shape = (modals.series_id.value_counts() == 700).sum()\n",
        "\n",
        "    if (modals.series_id.value_counts() == 700 ).sum() != len(labels) :\n",
        "        return \"Data sizes are incompatible, modal count = {} and label count = {}\".format(x_shape, len(labels) )\n",
        "\n",
        "    strn = \"Data sizes are - modal count = {} and label count = {}\".format(x_shape, len(labels) )\n",
        "    print(strn)\n",
        "    print(\" Modals and labels created ..\")\n",
        "\n",
        "\n",
        "    modals.drop(['series_id'], axis= 1, inplace = True)\n",
        "    columns = modals.columns\n",
        "\n",
        "    \n",
        "\n",
        "    # perform a robust scaler transform of the dataset\n",
        "    trans = MinMaxScaler()\n",
        "    modals = trans.fit_transform(modals)\n",
        "\n",
        "    modals = pd.DataFrame(modals,columns= columns)\n",
        "    modals['series_id'] = series_id\n",
        "\n",
        "\n",
        "    print(\"Data Normalized with MIn MAx scaler\")\n",
        "\n",
        "    return modals,labels"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KsyAVpQhtpK"
      },
      "source": [
        "FEATURE_COLUMNS = ['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjfX0DrbwJu5"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYgzoVE8oyC9"
      },
      "source": [
        "def create_standard_data(seq_data,y_train) :\n",
        "\n",
        "\n",
        "    # Features \n",
        "    FEATURE_COLUMNS = ['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
        "\n",
        "    print(\"Standardinging data\", end = \" \")\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "\n",
        "    for series_id, group in seq_data.groupby(\"series_id\") :\n",
        "        \n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        sequence_features = group[FEATURE_COLUMNS]\n",
        "        label = y_train[y_train.series_id == series_id].iloc[0].label\n",
        "\n",
        "        x = sequence_features.to_numpy()\n",
        "        x = scaler.fit_transform(x)\n",
        "\n",
        "        X.append(x)\n",
        "        y.append(label)\n",
        "        \n",
        "        # sequences.append((sequence_features, label))\n",
        "\n",
        "        # print(\"Sequences Created \")\n",
        "    print()    \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return X,y"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc7Df2YN1bAr"
      },
      "source": [
        "def get_train_data(file_num:int) :\n",
        "\n",
        "    print()\n",
        "    print(\"file num:{} \".format(file_num))\n",
        "    print()\n",
        "    \n",
        "    modals, labels = create_train_dataframe(file_num)\n",
        "\n",
        "    X,y = create_standard_data(modals,labels)\n",
        "\n",
        "    return X,y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxPJsbzihVxi"
      },
      "source": [
        "def get_test_data(file_num:int) :\n",
        "\n",
        "    print()\n",
        "    print(\"file num:{} \".format(file_num))\n",
        "    print()\n",
        "    \n",
        "    modals, labels = create_test_dataframe(file_num)\n",
        "\n",
        "    X,y = create_standard_data(modals,labels)\n",
        "\n",
        "    return X,y"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36VTFA2vG-VS"
      },
      "source": [
        "def create_train_data(train) :\n",
        "    \n",
        "    X_train, y_train = get_train_data(train[0])\n",
        "    # y_train = get_train_data(train[0])\n",
        "\n",
        "\n",
        "    for x in train[1:]:\n",
        "        tempx, tempy = get_train_data(x)\n",
        "        X_train = np.concatenate((X_train, tempx), axis = 0)\n",
        "        y_train = np.concatenate((y_train, tempy), axis = 0 )\n",
        "\n",
        "    print(\"Training Set Done !\")    \n",
        "\n",
        "\n",
        "    return X_train,y_train"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idtj96SShKfy"
      },
      "source": [
        "def create_test_data(test) :\n",
        "\n",
        "    X_test, y_test = get_test_data(test[0])\n",
        "\n",
        "\n",
        "    for x in test[1:]:\n",
        "        tempx, tempy = get_test_data(x)\n",
        "        X_test = np.concatenate([X_test, tempx])\n",
        "        y_test = np.concatenate([y_test, tempy])\n",
        "\n",
        "    print(\"Testing Loop Done !\")\n",
        "\n",
        "    return X_test, y_test"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbaYHOKwfyP-"
      },
      "source": [
        "train = [2,3,4,5,6,7,8,9,10,11,13,14]\n",
        "test = [15,16,17]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfdg8mB4f2Hc",
        "outputId": "dfdd5c30-4333-48ab-e844-aa2e4fe3e0e1"
      },
      "source": [
        "X_train,y_train = create_test_data(train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "file num:2 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2121 and label count = 2121\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:3 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2155 and label count = 2155\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:4 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2165 and label count = 2165\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:5 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2217 and label count = 2217\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:6 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2202 and label count = 2202\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:7 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2198 and label count = 2198\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:8 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2209 and label count = 2209\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:9 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2197 and label count = 2197\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:10 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2277 and label count = 2277\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:11 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2228 and label count = 2228\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:13 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2226 and label count = 2226\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:14 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2227 and label count = 2227\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "Testing Loop Done !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pJbcPASi2oo",
        "outputId": "5881bae1-d7b9-4aa0-c367-458357297029"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26422, 700, 8), (26422,))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jInqq8ZDins4",
        "outputId": "2c758f41-35db-41b6-cd87-bf230a2e88da"
      },
      "source": [
        "X_test,y_test = create_test_data(test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "file num:15 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2233 and label count = 2233\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:16 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2221 and label count = 2221\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "\n",
            "file num:17 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2276 and label count = 2276\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n",
            "Testing Loop Done !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Z6IzR_mdKl",
        "outputId": "a462d47e-4c0d-42ff-ba9c-49f22b70c8fe"
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6730, 700, 8), (6730,))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRgfHVPUwomK",
        "outputId": "3d68a418-43f7-46f9-9140-1c8c8b97c47e"
      },
      "source": [
        "num_classes = len(np.unique(y_train))\n",
        "num_classes"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UYMWiO4S9W"
      },
      "source": [
        "n_classes = num_classes"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMWzzeN4w4Rz"
      },
      "source": [
        "idx = np.random.permutation(len(X_train))\n",
        "X_train = X_train[idx]\n",
        "y_train = y_train[idx]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9M88Q6XxJ7u"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4STFJii5rh-"
      },
      "source": [
        "\n",
        "\n",
        "### Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4mTEFl13ymU"
      },
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nQc9bVH36Gs"
      },
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEPOTf-g6OW6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNnGu7mb9Vyf"
      },
      "source": [
        "# fix this line "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXigPbR-6IDx"
      },
      "source": [
        "X_train, _ , y_train, _  = train_test_split(X_train, y_train , test_size = 0.5 , random_state = 42)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e08w_9h6pNS",
        "outputId": "cb365446-9c25-4fe6-a685-684b8b5e487d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13211, 700, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWsb32Sg9NWu",
        "outputId": "c4d9c6b3-ed17-4666-cf8a-3e125df33ce2"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13211,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPGgJBol5v82"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddMV8YWuxUlb",
        "outputId": "1d219df4-5f6c-4957-abd6-abc9e0f42f32"
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 700, 8)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization (LayerNorma (None, 700, 8)       16          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention (MultiHead (None, 700, 8)       35848       layer_normalization[0][0]        \n",
            "                                                                 layer_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 700, 8)       0           multi_head_attention[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 700, 8)       0           dropout[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNor (None, 700, 8)       16          tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 700, 4)       36          layer_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 700, 4)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 700, 8)       40          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 700, 8)       0           conv1d_1[0][0]                   \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNor (None, 700, 8)       16          tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_1 (MultiHe (None, 700, 8)       35848       layer_normalization_2[0][0]      \n",
            "                                                                 layer_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 700, 8)       0           multi_head_attention_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 700, 8)       0           dropout_2[0][0]                  \n",
            "                                                                 tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNor (None, 700, 8)       16          tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 700, 4)       36          layer_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 700, 4)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 700, 8)       40          dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 700, 8)       0           conv1d_3[0][0]                   \n",
            "                                                                 tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNor (None, 700, 8)       16          tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_2 (MultiHe (None, 700, 8)       35848       layer_normalization_4[0][0]      \n",
            "                                                                 layer_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 700, 8)       0           multi_head_attention_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 700, 8)       0           dropout_4[0][0]                  \n",
            "                                                                 tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNor (None, 700, 8)       16          tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 700, 4)       36          layer_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 700, 4)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 700, 8)       40          dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 700, 8)       0           conv1d_5[0][0]                   \n",
            "                                                                 tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNor (None, 700, 8)       16          tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_3 (MultiHe (None, 700, 8)       35848       layer_normalization_6[0][0]      \n",
            "                                                                 layer_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 700, 8)       0           multi_head_attention_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam (None, 700, 8)       0           dropout_6[0][0]                  \n",
            "                                                                 tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_7 (LayerNor (None, 700, 8)       16          tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 700, 4)       36          layer_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 700, 4)       0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 700, 8)       40          dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 700, 8)       0           conv1d_7[0][0]                   \n",
            "                                                                 tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 700)          0           tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          89728       global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3)            387         dropout_8[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 233,939\n",
            "Trainable params: 233,939\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "145/145 [==============================] - 356s 2s/step - loss: 1.1701 - sparse_categorical_accuracy: 0.4530 - val_loss: 1.0060 - val_sparse_categorical_accuracy: 0.5454\n",
            "Epoch 2/50\n",
            "145/145 [==============================] - 326s 2s/step - loss: 1.0219 - sparse_categorical_accuracy: 0.5268 - val_loss: 0.9822 - val_sparse_categorical_accuracy: 0.5545\n",
            "Epoch 3/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.9931 - sparse_categorical_accuracy: 0.5413 - val_loss: 0.9664 - val_sparse_categorical_accuracy: 0.5694\n",
            "Epoch 4/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.9735 - sparse_categorical_accuracy: 0.5618 - val_loss: 0.9556 - val_sparse_categorical_accuracy: 0.5749\n",
            "Epoch 5/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.9512 - sparse_categorical_accuracy: 0.5766 - val_loss: 0.9232 - val_sparse_categorical_accuracy: 0.6024\n",
            "Epoch 6/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.9156 - sparse_categorical_accuracy: 0.6109 - val_loss: 0.8951 - val_sparse_categorical_accuracy: 0.6289\n",
            "Epoch 7/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.8923 - sparse_categorical_accuracy: 0.6201 - val_loss: 0.8778 - val_sparse_categorical_accuracy: 0.6362\n",
            "Epoch 8/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.8812 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.8670 - val_sparse_categorical_accuracy: 0.6340\n",
            "Epoch 9/50\n",
            "145/145 [==============================] - 328s 2s/step - loss: 0.8670 - sparse_categorical_accuracy: 0.6385 - val_loss: 0.8583 - val_sparse_categorical_accuracy: 0.6511\n",
            "Epoch 10/50\n",
            "145/145 [==============================] - 328s 2s/step - loss: 0.8457 - sparse_categorical_accuracy: 0.6498 - val_loss: 0.8425 - val_sparse_categorical_accuracy: 0.6536\n",
            "Epoch 11/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.8415 - sparse_categorical_accuracy: 0.6540 - val_loss: 0.8412 - val_sparse_categorical_accuracy: 0.6501\n",
            "Epoch 12/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.8217 - sparse_categorical_accuracy: 0.6630 - val_loss: 0.8329 - val_sparse_categorical_accuracy: 0.6637\n",
            "Epoch 13/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.8132 - sparse_categorical_accuracy: 0.6645 - val_loss: 0.8496 - val_sparse_categorical_accuracy: 0.6428\n",
            "Epoch 14/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.8131 - sparse_categorical_accuracy: 0.6688 - val_loss: 0.8419 - val_sparse_categorical_accuracy: 0.6483\n",
            "Epoch 15/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7954 - sparse_categorical_accuracy: 0.6722 - val_loss: 0.8511 - val_sparse_categorical_accuracy: 0.6440\n",
            "Epoch 16/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7874 - sparse_categorical_accuracy: 0.6789 - val_loss: 0.8230 - val_sparse_categorical_accuracy: 0.6642\n",
            "Epoch 17/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7792 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.8047 - val_sparse_categorical_accuracy: 0.6753\n",
            "Epoch 18/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7659 - sparse_categorical_accuracy: 0.6858 - val_loss: 0.8096 - val_sparse_categorical_accuracy: 0.6799\n",
            "Epoch 19/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7537 - sparse_categorical_accuracy: 0.6893 - val_loss: 0.8077 - val_sparse_categorical_accuracy: 0.6821\n",
            "Epoch 20/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7550 - sparse_categorical_accuracy: 0.6930 - val_loss: 0.8010 - val_sparse_categorical_accuracy: 0.6829\n",
            "Epoch 21/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7507 - sparse_categorical_accuracy: 0.6942 - val_loss: 0.8170 - val_sparse_categorical_accuracy: 0.6683\n",
            "Epoch 22/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7339 - sparse_categorical_accuracy: 0.6993 - val_loss: 0.8066 - val_sparse_categorical_accuracy: 0.6720\n",
            "Epoch 23/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.7193 - sparse_categorical_accuracy: 0.7049 - val_loss: 0.7949 - val_sparse_categorical_accuracy: 0.6758\n",
            "Epoch 24/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.7138 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.7909 - val_sparse_categorical_accuracy: 0.6837\n",
            "Epoch 25/50\n",
            "145/145 [==============================] - 328s 2s/step - loss: 0.7044 - sparse_categorical_accuracy: 0.7068 - val_loss: 0.7988 - val_sparse_categorical_accuracy: 0.6761\n",
            "Epoch 26/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6947 - sparse_categorical_accuracy: 0.7118 - val_loss: 0.8006 - val_sparse_categorical_accuracy: 0.6781\n",
            "Epoch 27/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6879 - sparse_categorical_accuracy: 0.7188 - val_loss: 0.7909 - val_sparse_categorical_accuracy: 0.6831\n",
            "Epoch 28/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6784 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.7894 - val_sparse_categorical_accuracy: 0.6844\n",
            "Epoch 29/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.6702 - sparse_categorical_accuracy: 0.7247 - val_loss: 0.7918 - val_sparse_categorical_accuracy: 0.6826\n",
            "Epoch 30/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6644 - sparse_categorical_accuracy: 0.7252 - val_loss: 0.7949 - val_sparse_categorical_accuracy: 0.6839\n",
            "Epoch 31/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.6584 - sparse_categorical_accuracy: 0.7249 - val_loss: 0.7909 - val_sparse_categorical_accuracy: 0.6814\n",
            "Epoch 32/50\n",
            "145/145 [==============================] - 329s 2s/step - loss: 0.6441 - sparse_categorical_accuracy: 0.7293 - val_loss: 0.7913 - val_sparse_categorical_accuracy: 0.6806\n",
            "Epoch 33/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6360 - sparse_categorical_accuracy: 0.7363 - val_loss: 0.7937 - val_sparse_categorical_accuracy: 0.6801\n",
            "Epoch 34/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6274 - sparse_categorical_accuracy: 0.7372 - val_loss: 0.7982 - val_sparse_categorical_accuracy: 0.6776\n",
            "Epoch 35/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6148 - sparse_categorical_accuracy: 0.7448 - val_loss: 0.7998 - val_sparse_categorical_accuracy: 0.6801\n",
            "Epoch 36/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6126 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.8052 - val_sparse_categorical_accuracy: 0.6796\n",
            "Epoch 37/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.6004 - sparse_categorical_accuracy: 0.7472 - val_loss: 0.7990 - val_sparse_categorical_accuracy: 0.6773\n",
            "Epoch 38/50\n",
            "145/145 [==============================] - 330s 2s/step - loss: 0.5858 - sparse_categorical_accuracy: 0.7612 - val_loss: 0.8077 - val_sparse_categorical_accuracy: 0.6811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v00Ng4bpmusy"
      },
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.3,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuZspXYfBa2O"
      },
      "source": [
        "model.save('attention.h5')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szznPBzKusQw"
      },
      "source": [
        "model = keras.models.load_model(\"attention.h5\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yfqBCRly7y_"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qD7Ucdby0hb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "02195309-6e55-4ca8-c5d6-614cb4a83fea"
      },
      "source": [
        "metric = \"sparse_categorical_accuracy\"\n",
        "plt.figure()\n",
        "plt.plot(history.history[metric])\n",
        "plt.plot(history.history[\"val_\" + metric])\n",
        "plt.title(\"model \" + metric)\n",
        "plt.ylabel(metric, fontsize=\"large\")\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWS0DwuZ5mKv"
      },
      "source": [
        "# Testing Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHBhaHwA0SGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511d3eaa-fe09-4b18-9d41-c00a9b5347c5"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211/211 [==============================] - 70s 330ms/step - loss: 0.8401 - sparse_categorical_accuracy: 0.6678\n",
            "Test accuracy 0.6677563190460205\n",
            "Test loss 0.8401078581809998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYyAvsm3unLM"
      },
      "source": [
        "def ptest_acc(X_test,y_test ) : \n",
        "\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "    print(\"Test accuracy\", test_acc)\n",
        "    print(\"Test loss\", test_loss)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE-LCC8RwxDX"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rua4ExfaweXw"
      },
      "source": [
        "def confu(X,y_true) :\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X), axis = 1)\n",
        "    cnm = confusion_matrix(y_true, y_pred)\n",
        "    cp = classification_report(y_true, y_pred)\n",
        "\n",
        "    print(\"confusion matrix\")\n",
        "    print(cnm)\n",
        "    print(\"classification report\")\n",
        "    print(cp)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI3ZEiZ_u38f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e37e58c-92a0-498e-b5cd-d8a01dcc4e1f"
      },
      "source": [
        "X15, y15 = get_test_data(15)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "file num:15 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2233 and label count = 2233\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJGpkYCXw8W8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbc9a12-a404-4947-fe7a-881c352aa893"
      },
      "source": [
        "confu(X15,y15)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix\n",
            "[[1085   89    1]\n",
            " [ 552  132    2]\n",
            " [ 365    5    2]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.92      0.68      1175\n",
            "           1       0.58      0.19      0.29       686\n",
            "           2       0.40      0.01      0.01       372\n",
            "\n",
            "    accuracy                           0.55      2233\n",
            "   macro avg       0.51      0.37      0.33      2233\n",
            "weighted avg       0.53      0.55      0.45      2233\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeIxQZrXvHS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34b6a8e-fd71-485f-c2d4-04d451b34c47"
      },
      "source": [
        "X16, y16 = get_test_data(16)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "file num:16 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2221 and label count = 2221\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ad51oIjxZFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f66437f-d09f-4245-f8e0-ca2b39506df9"
      },
      "source": [
        "confu(X16,y16)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix\n",
            "[[1131   45    4]\n",
            " [ 134  535    4]\n",
            " [ 346   22    0]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.96      0.81      1180\n",
            "           1       0.89      0.79      0.84       673\n",
            "           2       0.00      0.00      0.00       368\n",
            "\n",
            "    accuracy                           0.75      2221\n",
            "   macro avg       0.53      0.58      0.55      2221\n",
            "weighted avg       0.64      0.75      0.68      2221\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV9IopOLvSkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4058ac-a32e-4010-cbee-8c8c626fb54f"
      },
      "source": [
        "X17, y17 = get_test_data(17)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "file num:17 \n",
            "\n",
            "Index(['ACCX', 'ACCY', 'ACCZ', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp', 'label',\n",
            "       'series_id'],\n",
            "      dtype='object')\n",
            "Data sizes are - modal count = 2276 and label count = 2276\n",
            " Modals and labels created ..\n",
            "Data Normalized with MIn MAx scaler\n",
            "Standardinging data \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG244ajuy5go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4966776b-8e16-4f3f-939f-93bd8d31ed4c"
      },
      "source": [
        "confu(X17,y17)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix\n",
            "[[1095   80    6]\n",
            " [ 211  512    0]\n",
            " [ 307   63    2]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.93      0.78      1181\n",
            "           1       0.78      0.71      0.74       723\n",
            "           2       0.25      0.01      0.01       372\n",
            "\n",
            "    accuracy                           0.71      2276\n",
            "   macro avg       0.57      0.55      0.51      2276\n",
            "weighted avg       0.64      0.71      0.64      2276\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiPNT2YYzUkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0adb0fe5-6754-4ca9-97f3-784b8ba99897"
      },
      "source": [
        "confu(X_test, y_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix\n",
            "[[3311  214   11]\n",
            " [ 897 1179    6]\n",
            " [1018   90    4]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.94      0.76      3536\n",
            "           1       0.80      0.57      0.66      2082\n",
            "           2       0.19      0.00      0.01      1112\n",
            "\n",
            "    accuracy                           0.67      6730\n",
            "   macro avg       0.54      0.50      0.47      6730\n",
            "weighted avg       0.61      0.67      0.60      6730\n",
            "\n"
          ]
        }
      ]
    }
  ]
}